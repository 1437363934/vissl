<!DOCTYPE html><html lang=""><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>VISSL · A library for state-of-the-art self-supervised learning</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="A library for state-of-the-art self-supervised learning"/><meta property="og:title" content="VISSL · A library for state-of-the-art self-supervised learning"/><meta property="og:type" content="website"/><meta property="og:url" content="https://vissl.ai/"/><meta property="og:description" content="A library for state-of-the-art self-supervised learning"/><meta property="og:image" content="https://vissl.ai/img/vissllogo.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://vissl.ai/img/vissllogo.svg"/><link rel="shortcut icon" href="/img/visslfavicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-172675973-1', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/visslfavicon.png" alt="VISSL"/><h2 class="headerTitleWithLogo">VISSL</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/tutorials" target="_self">Tutorials</a></li><li class=""><a href="https://vissl.readthedocs.io/" target="_self">Docs</a></li><li class=""><a href="https://github.com/facebookresearch/vissl" target="_self">GitHub</a></li><li class=""><a target="_self"></a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span></span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Tutorials</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/">Overview</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Getting Started</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Installation">Installation</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Understanding_VISSL_Training_and_YAML_Config">Understanding VISSL Training and YAML Config</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Training</h3><ul class=""><li class="navListItem navListItemActive"><a class="navItem" href="/tutorials/Train_SimCLR_on_1_gpu">Train SimCLR on 1-gpu</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Feature Extraction</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Feature_Extraction">Feature Extraction</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Benchmark</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Benchmark_Linear_Image_Classification_on_ImageNet_1K">Benchmark Linear Image Classification on ImageNet-1K</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Benchmark_Full_Finetuning_on_ImageNet_1K">Benchmark Full-Finetuning on ImageNet-1K</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Large Scale Training</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Large_Scale_Training">Large Scale Training with VISSL (fp16, LARC, ZeRO, etc)</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="tutorialButtonsWrapper"><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="https://colab.research.google.com/github/facebookresearch/vissl/blob/master/tutorials/Train_SimCLR_on_1_gpu.ipynb" target="_blank"><img class="colabButton" align="left" src="/img/colab_icon.png"/>Run in Google Colab</a></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="/files/Train_SimCLR_on_1_gpu.ipynb" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Jupyter Notebook</a></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="/files/Train_SimCLR_on_1_gpu.py" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Source Code</a></div></div><div class="tutorialBody">
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js">
</script>
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js">
</script>
<div class="notebook">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Training-SimCLR-on-1-gpu-with-VISSL">Training SimCLR on 1-gpu with VISSL<a class="anchor-link" href="#Training-SimCLR-on-1-gpu-with-VISSL">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial, we demonstrate how to use VISSL to train a self-supervsied model using <a href="https://arxiv.org/abs/2002.05709">SimCLR</a> approach. We use 1-gpu for this training.</p>
<p>You can make a copy of this tutorial by "File -&gt; Open in playground mode" and make changes there. <strong>DO NOT</strong> request access to this tutorial.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>NOTE:</strong> Please ensure your Collab Notebook has GPU available. To ensure/select this, simple follow: <code>Edit -&gt; Notebook Settings -&gt; select GPU</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install-VISSL">Install VISSL<a class="anchor-link" href="#Install-VISSL">¶</a></h2><p>Installing VISSL is pretty straightfoward. We will use pip binaries of VISSL and follow instructions from <a href="https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package">here</a>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Install: PyTorch (we assume 1.5.1 but VISSL works with all PyTorch versions &gt;=1.4)</span>
<span class="o">!</span>pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.5.1+cu101 <span class="nv">torchvision</span><span class="o">==</span><span class="m">0</span>.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html

<span class="c1"># install opencv</span>
<span class="o">!</span>pip install opencv-python

<span class="c1"># install apex by checking system settings: cuda version, pytorch version, python version</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">version_str</span><span class="o">=</span><span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">([</span>
    <span class="sa">f</span><span class="s2">"py3</span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="o">.</span><span class="n">minor</span><span class="si">}</span><span class="s2">_cu"</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"."</span><span class="p">,</span><span class="s2">""</span><span class="p">),</span>
    <span class="sa">f</span><span class="s2">"_pyt</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span>
<span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">version_str</span><span class="p">)</span>

<span class="c1"># install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)</span>
<span class="o">!</span>pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/<span class="o">{</span>version_str<span class="o">}</span>/download.html

<span class="c1"># install VISSL</span>
<span class="o">!</span>pip install vissl
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>VISSL should be successfuly installed by now and all the dependencies should be available.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">vissl</span>
<span class="kn">import</span> <span class="nn">tensorboard</span>
<span class="kn">import</span> <span class="nn">apex</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="SimCLR-example-config-file">SimCLR example config file<a class="anchor-link" href="#SimCLR-example-config-file">¶</a></h2><p>VISSL provides yaml configuration files that reproduce training of all self-supervised approaches <a href="https://github.com/facebookresearch/vissl/tree/master/configs/config/pretrain">here</a>.</p>
<p>For the purpose of this tutorial, we will use the config file for training SimCLR approach on 1-gpu. Let's go ahead and download the <a href="https://github.com/facebookresearch/vissl/blob/master/configs/config/test/integration_test/quick_simclr.yaml">example config file</a>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>mkdir -p configs/config/
<span class="o">!</span>wget -O configs/__init__.py https://dl.fbaipublicfiles.com/vissl/tutorials/configs/__init__.py 
<span class="o">!</span>wget -O configs/config/quick_1gpu_resnet50_simclr.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/quick_1gpu_resnet50_simclr.yaml
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Builtin-training-tool-in-python">Builtin training tool in python<a class="anchor-link" href="#Builtin-training-tool-in-python">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>VISSL also provides a <a href="https://github.com/facebookresearch/vissl/blob/master/tools/run_distributed_engines.py">helper python tool</a> that allows to use VISSL for training purposes. This tool offers:</p>
<ul>
<li>allows training and feature extraction both using VISSL. </li>
<li>also allows training on 1-gpu or multi-gpu. </li>
<li>can be used to launch multi-machine distributed training.</li>
</ul>
<p>Let's go ahead and download this tool directly.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>--2021-01-25 19:47:58--  https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py
Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...
Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 6568 (6.4K) [text/x-python]
Saving to: ‘run_distributed_engines.py’

run_distributed_eng 100%[===================&gt;]   6.41K  --.-KB/s    in 0s      

2021-01-25 19:47:59 (25.1 MB/s) - ‘run_distributed_engines.py’ saved [6568/6568]

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train">Train<a class="anchor-link" href="#Train">¶</a></h2><p>We are ready to train now. For the purpose of training, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>python3 run_distributed_engines.py <span class="err">\</span>
    <span class="n">hydra</span><span class="o">.</span><span class="n">verbose</span><span class="o">=</span><span class="n">true</span> \
    <span class="n">config</span><span class="o">=</span><span class="n">quick_1gpu_resnet50_simclr</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATA_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">synthetic</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">CHECKPOINT</span><span class="o">.</span><span class="n">DIR</span><span class="o">=</span><span class="s2">"./checkpoints"</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">TENSORBOARD_SETUP</span><span class="o">.</span><span class="n">USE_TENSORBOARD</span><span class="o">=</span><span class="n">true</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

####### overrides: ['hydra.verbose=true', 'config=quick_1gpu_resnet50_simclr', 'config.DATA.TRAIN.DATA_SOURCES=[synthetic]', 'config.CHECKPOINT.DIR=./checkpoints', 'config.TENSORBOARD_SETUP.USE_TENSORBOARD=true', 'hydra.verbose=true']
INFO 2021-01-25 19:48:10,197 __init__.py:  32: Provided Config has latest version: 1
[PathManager] Attempting to register prefix 'http://' from the following call stack:
  File "run_distributed_engines.py", line 194, in &lt;module&gt;
    hydra_main(overrides=overrides)
  File "run_distributed_engines.py", line 179, in hydra_main
    hook_generator=default_hook_generator,
  File "run_distributed_engines.py", line 77, in launch_distributed
    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)
  File "/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py", line 31, in set_env_vars
    PathManager.register_handler(HTTPURLHandler(), allow_override=True)
  File "/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py", line 287, in register_handler
    + "".join(traceback.format_stack(limit=5))

[PathManager] Prefix 'http://' is already registered by &lt;class 'iopath.common.file_io.HTTPURLHandler'&gt;. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.
[PathManager] Attempting to register prefix 'https://' from the following call stack:
  File "run_distributed_engines.py", line 194, in &lt;module&gt;
    hydra_main(overrides=overrides)
  File "run_distributed_engines.py", line 179, in hydra_main
    hook_generator=default_hook_generator,
  File "run_distributed_engines.py", line 77, in launch_distributed
    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)
  File "/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py", line 31, in set_env_vars
    PathManager.register_handler(HTTPURLHandler(), allow_override=True)
  File "/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py", line 287, in register_handler
    + "".join(traceback.format_stack(limit=5))

[PathManager] Prefix 'https://' is already registered by &lt;class 'iopath.common.file_io.HTTPURLHandler'&gt;. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.
[PathManager] Attempting to register prefix 'ftp://' from the following call stack:
  File "run_distributed_engines.py", line 194, in &lt;module&gt;
    hydra_main(overrides=overrides)
  File "run_distributed_engines.py", line 179, in hydra_main
    hook_generator=default_hook_generator,
  File "run_distributed_engines.py", line 77, in launch_distributed
    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)
  File "/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py", line 31, in set_env_vars
    PathManager.register_handler(HTTPURLHandler(), allow_override=True)
  File "/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py", line 287, in register_handler
    + "".join(traceback.format_stack(limit=5))

[PathManager] Prefix 'ftp://' is already registered by &lt;class 'iopath.common.file_io.HTTPURLHandler'&gt;. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.
INFO 2021-01-25 19:48:10,199 run_distributed_engines.py: 163: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:58591
[PathManager] Attempting to register prefix 'http://' from the following call stack:
  File "run_distributed_engines.py", line 166, in _distributed_worker
    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)
  File "run_distributed_engines.py", line 159, in process_main
    hook_generator=hook_generator,
  File "/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py", line 60, in train_main
    set_env_vars(local_rank, node_id, cfg)
  File "/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py", line 31, in set_env_vars
    PathManager.register_handler(HTTPURLHandler(), allow_override=True)
  File "/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py", line 287, in register_handler
    + "".join(traceback.format_stack(limit=5))

[PathManager] Prefix 'http://' is already registered by &lt;class 'iopath.common.file_io.HTTPURLHandler'&gt;. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.
[PathManager] Attempting to register prefix 'https://' from the following call stack:
  File "run_distributed_engines.py", line 166, in _distributed_worker
    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)
  File "run_distributed_engines.py", line 159, in process_main
    hook_generator=hook_generator,
  File "/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py", line 60, in train_main
    set_env_vars(local_rank, node_id, cfg)
  File "/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py", line 31, in set_env_vars
    PathManager.register_handler(HTTPURLHandler(), allow_override=True)
  File "/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py", line 287, in register_handler
    + "".join(traceback.format_stack(limit=5))

[PathManager] Prefix 'https://' is already registered by &lt;class 'iopath.common.file_io.HTTPURLHandler'&gt;. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.
[PathManager] Attempting to register prefix 'ftp://' from the following call stack:
  File "run_distributed_engines.py", line 166, in _distributed_worker
    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)
  File "run_distributed_engines.py", line 159, in process_main
    hook_generator=hook_generator,
  File "/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py", line 60, in train_main
    set_env_vars(local_rank, node_id, cfg)
  File "/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py", line 31, in set_env_vars
    PathManager.register_handler(HTTPURLHandler(), allow_override=True)
  File "/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py", line 287, in register_handler
    + "".join(traceback.format_stack(limit=5))

[PathManager] Prefix 'ftp://' is already registered by &lt;class 'iopath.common.file_io.HTTPURLHandler'&gt;. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.
INFO 2021-01-25 19:48:10,200 train.py:  66: Env set for rank: 0, dist_rank: 0
INFO 2021-01-25 19:48:10,201 env.py:  41: CLICOLOR:	1
INFO 2021-01-25 19:48:10,201 env.py:  41: CLOUDSDK_CONFIG:	/content/.config
INFO 2021-01-25 19:48:10,201 env.py:  41: CLOUDSDK_PYTHON:	python3
INFO 2021-01-25 19:48:10,201 env.py:  41: COLAB_GPU:	1
INFO 2021-01-25 19:48:10,201 env.py:  41: CUDA_PKG_VERSION:	10-1=10.1.243-1
INFO 2021-01-25 19:48:10,201 env.py:  41: CUDA_VERSION:	10.1.243
INFO 2021-01-25 19:48:10,201 env.py:  41: CUDNN_VERSION:	7.6.5.32
INFO 2021-01-25 19:48:10,201 env.py:  41: DATALAB_SETTINGS_OVERRIDES:	{"kernelManagerProxyPort":6000,"kernelManagerProxyHost":"172.28.0.3","jupyterArgs":["--ip=\"172.28.0.2\""],"debugAdapterMultiplexerPath":"/usr/local/bin/dap_multiplexer"}
INFO 2021-01-25 19:48:10,201 env.py:  41: DEBIAN_FRONTEND:	noninteractive
INFO 2021-01-25 19:48:10,201 env.py:  41: ENV:	/root/.bashrc
INFO 2021-01-25 19:48:10,201 env.py:  41: GCE_METADATA_TIMEOUT:	0
INFO 2021-01-25 19:48:10,201 env.py:  41: GCS_READ_CACHE_BLOCK_SIZE_MB:	16
INFO 2021-01-25 19:48:10,201 env.py:  41: GIT_PAGER:	cat
INFO 2021-01-25 19:48:10,201 env.py:  41: GLIBCPP_FORCE_NEW:	1
INFO 2021-01-25 19:48:10,202 env.py:  41: GLIBCXX_FORCE_NEW:	1
INFO 2021-01-25 19:48:10,202 env.py:  41: HOME:	/root
INFO 2021-01-25 19:48:10,202 env.py:  41: HOSTNAME:	442a82988f4e
INFO 2021-01-25 19:48:10,202 env.py:  41: JPY_PARENT_PID:	50
INFO 2021-01-25 19:48:10,202 env.py:  41: LANG:	en_US.UTF-8
INFO 2021-01-25 19:48:10,202 env.py:  41: LAST_FORCED_REBUILD:	20210119
INFO 2021-01-25 19:48:10,202 env.py:  41: LD_LIBRARY_PATH:	/usr/lib64-nvidia
INFO 2021-01-25 19:48:10,202 env.py:  41: LD_PRELOAD:	/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4
INFO 2021-01-25 19:48:10,202 env.py:  41: LIBRARY_PATH:	/usr/local/cuda/lib64/stubs
INFO 2021-01-25 19:48:10,202 env.py:  41: LOCAL_RANK:	0
INFO 2021-01-25 19:48:10,202 env.py:  41: MPLBACKEND:	module://ipykernel.pylab.backend_inline
INFO 2021-01-25 19:48:10,202 env.py:  41: NCCL_VERSION:	2.8.3
INFO 2021-01-25 19:48:10,202 env.py:  41: NO_GCE_CHECK:	True
INFO 2021-01-25 19:48:10,202 env.py:  41: NVIDIA_DRIVER_CAPABILITIES:	compute,utility
INFO 2021-01-25 19:48:10,203 env.py:  41: NVIDIA_REQUIRE_CUDA:	cuda&gt;=10.1 brand=tesla,driver&gt;=396,driver&lt;397 brand=tesla,driver&gt;=410,driver&lt;411 brand=tesla,driver&gt;=418,driver&lt;419
INFO 2021-01-25 19:48:10,203 env.py:  41: NVIDIA_VISIBLE_DEVICES:	all
INFO 2021-01-25 19:48:10,203 env.py:  41: OLDPWD:	/
INFO 2021-01-25 19:48:10,203 env.py:  41: PAGER:	cat
INFO 2021-01-25 19:48:10,203 env.py:  41: PATH:	/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin
INFO 2021-01-25 19:48:10,203 env.py:  41: PWD:	/content
INFO 2021-01-25 19:48:10,203 env.py:  41: PYTHONPATH:	/env/python
INFO 2021-01-25 19:48:10,203 env.py:  41: PYTHONWARNINGS:	ignore:::pip._internal.cli.base_command
INFO 2021-01-25 19:48:10,203 env.py:  41: RANK:	0
INFO 2021-01-25 19:48:10,203 env.py:  41: SHELL:	/bin/bash
INFO 2021-01-25 19:48:10,203 env.py:  41: SHLVL:	1
INFO 2021-01-25 19:48:10,203 env.py:  41: TBE_CREDS_ADDR:	172.28.0.1:8008
INFO 2021-01-25 19:48:10,203 env.py:  41: TERM:	xterm-color
INFO 2021-01-25 19:48:10,203 env.py:  41: TF_FORCE_GPU_ALLOW_GROWTH:	true
INFO 2021-01-25 19:48:10,203 env.py:  41: WORLD_SIZE:	1
INFO 2021-01-25 19:48:10,203 env.py:  41: _:	/usr/bin/python3
INFO 2021-01-25 19:48:10,203 env.py:  41: __EGL_VENDOR_LIBRARY_DIRS:	/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/
INFO 2021-01-25 19:48:10,203 misc.py:  86: Set start method of multiprocessing to forkserver
INFO 2021-01-25 19:48:10,204 train.py:  77: Setting seed....
INFO 2021-01-25 19:48:10,204 misc.py:  99: MACHINE SEED: 0
INFO 2021-01-25 19:48:10,242 hydra_config.py: 140: Training with config:
INFO 2021-01-25 19:48:10,247 hydra_config.py: 144: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': './checkpoints',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': True,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'LAYER_NAME': ''},
                'NUM_CLUSTERS': 16000,
                'N_ITER': 50},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 5,
          'PIN_MEMORY': True,
          'TEST': {'BATCHSIZE_PER_REPLICA': 256,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['imagenet1k_folder'],
                   'DATA_LIMIT': -1,
                   'DATA_PATHS': [],
                   'DATA_SOURCES': [],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': [],
                   'LABEL_TYPE': 'sample_index',
                   'MMAP_MODE': True,
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [],
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BATCHSIZE_PER_REPLICA': 32,
                    'COLLATE_FUNCTION': 'simclr_collator',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['imagenet1k_filelist'],
                    'DATA_LIMIT': 500,
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['synthetic'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': True,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': [],
                    'LABEL_TYPE': 'sample_index',
                    'MMAP_MODE': True,
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'ImgReplicatePil', 'num_times': 2},
                                   {'name': 'RandomResizedCrop', 'size': 224},
                                   {'name': 'RandomHorizontalFlip', 'p': 0.5},
                                   {'name': 'ImgPilColorDistortion',
                                    'strength': 1.0},
                                   {'name': 'ImgPilGaussianBlur',
                                    'p': 0.5,
                                    'radius_max': 2.0,
                                    'radius_min': 0.1},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'IMG_RETRIEVAL': {'DATASET_PATH': '',
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SHOULD_TRAIN_PCA_OR_WHITENING': True,
                   'SPATIAL_LEVELS': 3,
                   'TEMP_DIR': '/tmp/instance_retrieval/',
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 1,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'simclr_info_nce_loss',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 64,
                                                     'embedding_dim': 128,
                                                     'world_size': 1},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': [],
                                    'num_meters': 1,
                                    'topk_values': [1]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'name': ''},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'keep_batchnorm_fp32': True,
                                       'loss_scale': 'dynamic',
                                       'master_weights': True,
                                       'opt_level': 'O3'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': False,
                                     'EVAL_TRUNK_AND_HEAD': False,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,
                                     'FREEZE_TRUNK_AND_HEAD': False,
                                     'FREEZE_TRUNK_ONLY': False,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [],
                                     'SHOULD_FLATTEN_FEATS': True},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [['mlp',
                                {'dims': [2048, 2048], 'use_relu': True}],
                               ['mlp', {'dims': [2048, 128]}]],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,
                              'GROUP_SIZE': -1,
                              'SYNC_BN_TYPE': 'pytorch'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'NAME': 'resnet',
                     'RESNETS': {'DEPTH': 50},
                     'TRUNK_PARAMS': {'EFFICIENT_NETS': {},
                                      'REGNET': {},
                                      'RESNETS': {'DEPTH': 50,
                                                  'GROUPS': 1,
                                                  'LAYER4_STRIDE': 2,
                                                  'NORM': 'BatchNorm',
                                                  'WIDTH_MULTIPLIER': 1,
                                                  'WIDTH_PER_GROUP': 64,
                                                  'ZERO_INIT_RESIDUAL': False}}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': '',
                            'PARAMS_FILE': '',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': 'classy_state_dict'}},
 'MONITOR_PERF_STATS': True,
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 1e-06},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': False,
               'num_epochs': 2,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.3},
                                           'end_value': 0.0,
                                           'interval_scaling': ['rescaled',
                                                                'rescaled'],
                                           'lengths': [0.1, 0.9],
                                           'milestones': [30, 60],
                                           'name': 'composite',
                                           'schedulers': [{'end_value': 4.8,
                                                           'name': 'linear',
                                                           'start_value': 0.6},
                                                          {'end_value': 0.0048,
                                                           'is_adaptive': True,
                                                           'name': 'cosine_warm_restart',
                                                           'restart_interval_length': 0.334,
                                                           'start_value': 4.8,
                                                           'wave_type': 'full'}],
                                           'start_value': 0.1,
                                           'update_interval': 'step',
                                           'value': 0.1,
                                           'values': [0.1, 0.01, 0.001]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.3},
                                                'end_value': 0.0,
                                                'interval_scaling': ['rescaled',
                                                                     'rescaled'],
                                                'lengths': [0.1, 0.9],
                                                'milestones': [30, 60],
                                                'name': 'composite',
                                                'schedulers': [{'end_value': 4.8,
                                                                'name': 'linear',
                                                                'start_value': 0.6},
                                                               {'end_value': 0.0048,
                                                                'is_adaptive': True,
                                                                'name': 'cosine_warm_restart',
                                                                'restart_interval_length': 0.334,
                                                                'start_value': 4.8,
                                                                'wave_type': 'full'}],
                                                'start_value': 0.1,
                                                'update_interval': 'step',
                                                'value': 0.1,
                                                'values': [0.1, 0.01, 0.001]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': True,
               'weight_decay': 1e-06},
 'PERF_STAT_FREQUENCY': 10,
 'ROLLING_BTIME_FREQ': 5,
 'SEED_VALUE': 0,
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                       'FLUSH_EVERY_N_MIN': 5,
                       'LOG_DIR': '.',
                       'LOG_PARAMS': True,
                       'LOG_PARAMS_EVERY_N_ITERS': 310,
                       'LOG_PARAMS_GRADIENTS': True,
                       'USE_TENSORBOARD': True},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': False,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': False}
INFO 2021-01-25 19:48:10,517 train.py:  89: System config:
-------------------  ---------------------------------------------------------------
sys.platform         linux
Python               3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]
numpy                1.19.5
Pillow               7.0.0
vissl                0.1.5 @/usr/local/lib/python3.6/dist-packages/vissl
GPU available        True
GPU 0                Tesla T4
CUDA_HOME            /usr/local/cuda
torchvision          0.6.1+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision
hydra                1.0.5 @/usr/local/lib/python3.6/dist-packages/hydra
classy_vision        0.6.0.dev @/usr/local/lib/python3.6/dist-packages/classy_vision
tensorboard          1.15.0
apex                 0.1 @/usr/local/lib/python3.6/dist-packages/apex
cv2                  4.1.2
PyTorch              1.5.1+cu101 @/usr/local/lib/python3.6/dist-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

CPU info:
-------------------  ------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               2
On-line CPU(s) list  0,1
Thread(s) per core   2
Core(s) per socket   1
Socket(s)            1
NUMA node(s)         1
Vendor ID            GenuineIntel
CPU family           6
Model                79
Model name           Intel(R) Xeon(R) CPU @ 2.20GHz
Stepping             0
CPU MHz              2199.998
BogoMIPS             4399.99
Hypervisor vendor    KVM
Virtualization type  full
L1d cache            32K
L1i cache            32K
L2 cache             256K
L3 cache             56320K
NUMA node0 CPU(s)    0,1
-------------------  ------------------------------
INFO 2021-01-25 19:48:10,518 tensorboard.py:  46: Tensorboard dir: ./checkpoints/tb_logs
2021-01-25 19:48:12.717777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
INFO 2021-01-25 19:48:15,052 tensorboard_hook.py:  61: Setting up SSL Tensorboard Hook...
INFO 2021-01-25 19:48:15,052 tensorboard_hook.py:  67: Tensorboard config: log_params: True, log_params_freq: 310, log_params_gradients: True
INFO 2021-01-25 19:48:15,052 train_task.py: 192: Not using Automatic Mixed Precision
INFO 2021-01-25 19:48:15,053 trainer_main.py: 109: Using Distributed init method: tcp://localhost:58591, world_size: 1, rank: 0
INFO 2021-01-25 19:48:15,055 trainer_main.py: 130: | initialized host 442a82988f4e as rank 0 (0)
INFO 2021-01-25 19:48:15,055 img_replicate_pil.py:  49: ImgReplicatePil | Using num_times: 2
INFO 2021-01-25 19:48:15,055 img_pil_color_distortion.py:  53: ImgPilColorDistortion | Using strength: 1.0
INFO 2021-01-25 19:48:15,056 ssl_dataset.py: 130: Rank: 0 split: TRAIN Data files:
['']
INFO 2021-01-25 19:48:15,056 ssl_dataset.py: 133: Rank: 0 split: TRAIN Label files:
[]
INFO 2021-01-25 19:48:15,056 misc.py:  86: Set start method of multiprocessing to forkserver
INFO 2021-01-25 19:48:15,056 __init__.py:  91: Created the Distributed Sampler....
INFO 2021-01-25 19:48:15,056 __init__.py:  72: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 500, 'total_size': 500, 'shuffle': True}
INFO 2021-01-25 19:48:15,056 __init__.py: 155: Wrapping the dataloader to async device copies
INFO 2021-01-25 19:48:29,063 train_task.py: 419: Building model....
INFO 2021-01-25 19:48:29,063 resnext.py:  63: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2021-01-25 19:48:29,064 resnext.py:  83: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2021-01-25 19:48:29,687 model_helpers.py: 138: Using SyncBN group size: 1
INFO 2021-01-25 19:48:29,687 model_helpers.py: 153: Converting BN layers to PyTorch SyncBN
WARNING 2021-01-25 19:48:29,687 model_helpers.py: 159: Process groups not supported with PyTorch SyncBN currently. Traning will be slow. Please consider installing Apex for SyncBN.
INFO 2021-01-25 19:48:29,693 train_task.py: 591: Broadcast model BN buffers from master on every forward pass
INFO 2021-01-25 19:48:29,693 classification_task.py: 359: Synchronized Batch Normalization is disabled
INFO 2021-01-25 19:48:29,693 train_task.py: 340: Building loss...
INFO 2021-01-25 19:48:29,703 simclr_info_nce_loss.py:  88: Creating Info-NCE loss on Rank: 0
INFO 2021-01-25 19:48:29,752 optimizer_helper.py: 157: 
Trainable params: 163, 
Non-Trainable params: 0, 
Trunk Regularized Parameters: 53, 
Trunk Unregularized Parameters 106, 
Head Regularized Parameters: 4, 
Head Unregularized Parameters: 0 
Remaining Regularized Parameters: 0 
INFO 2021-01-25 19:48:29,752 trainer_main.py: 241: Training 2 epochs. One epoch = 15 iterations
INFO 2021-01-25 19:48:29,752 trainer_main.py: 243: Total 30 iterations for training
INFO 2021-01-25 19:48:29,752 trainer_main.py: 244: Total 500 samples in one epoch
INFO 2021-01-25 19:48:29,890 logger.py:  76: Mon Jan 25 19:48:29 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   37C    P0    27W /  70W |   1033MiB / 15079MiB |      1%      Default |
|                               |                      |                 ERR! |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

INFO 2021-01-25 19:48:29,892 trainer_main.py: 166: Model is:
 Classy &lt;class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'&gt;:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): ResNeXt(
    (_feature_blocks): ModuleDict(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1_relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(&lt;SUPPORTED_L4_STRIDE.two: 2&gt;, &lt;SUPPORTED_L4_STRIDE.two: 2&gt;), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(&lt;SUPPORTED_L4_STRIDE.two: 2&gt;, &lt;SUPPORTED_L4_STRIDE.two: 2&gt;), bias=False)
            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (flatten): Flatten()
    )
  )
  (heads): ModuleList(
    (0): MLP(
      (clf): Sequential(
        (0): Linear(in_features=2048, out_features=2048, bias=True)
        (1): ReLU(inplace=True)
      )
    )
    (1): MLP(
      (clf): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
      )
    )
  )
)
INFO 2021-01-25 19:48:29,945 trainer_main.py: 167: Loss is: { 'info_average': { 'dist_rank': 0,
  'name': 'SimclrInfoNCECriterion',
  'num_negatives': 62,
  'num_pos': 2,
  'temperature': 0.1},
  'name': 'SimclrInfoNCELoss'}
INFO 2021-01-25 19:48:29,945 trainer_main.py: 168: Starting training....
INFO 2021-01-25 19:48:29,945 __init__.py:  72: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 500, 'total_size': 500, 'shuffle': True}
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-01-25 19:48:37,960 trainer_main.py: 296: Phase advanced. Rank: 0
INFO 2021-01-25 19:48:42,223 state_update_hooks.py:  98: Starting phase 0 [train]
INFO 2021-01-25 19:48:48,167 tensorboard_hook.py: 188: Logging metrics. Iteration 1
INFO 2021-01-25 19:48:48,168 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 1; lr: 0.6; loss: 4.45957; btime(ms): 18415; eta: 0:08:54; peak_mem: 8007M
INFO 2021-01-25 19:48:48,780 tensorboard_hook.py: 188: Logging metrics. Iteration 2
INFO 2021-01-25 19:48:48,782 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 2; lr: 2.0; loss: 4.18492; btime(ms): 9514; eta: 0:04:26; peak_mem: 8007M
INFO 2021-01-25 19:48:49,396 tensorboard_hook.py: 188: Logging metrics. Iteration 3
INFO 2021-01-25 19:48:49,398 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 3; lr: 3.4; loss: 4.16275; btime(ms): 6548; eta: 0:02:56; peak_mem: 8007M
INFO 2021-01-25 19:48:50,003 tensorboard_hook.py: 188: Logging metrics. Iteration 4
INFO 2021-01-25 19:48:50,005 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 4; lr: 3.59685; loss: 4.16412; btime(ms): 5063; eta: 0:02:11; peak_mem: 8007M
INFO 2021-01-25 19:48:50,603 tensorboard_hook.py: 188: Logging metrics. Iteration 5
INFO 2021-01-25 19:48:50,605 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 5; lr: 3.48896; loss: 4.13283; btime(ms): 4170; eta: 0:01:44; peak_mem: 8007M; btime(5iters): 4170 ms; rolling_eta: 0:01:44
INFO 2021-01-25 19:48:51,213 tensorboard_hook.py: 188: Logging metrics. Iteration 6
INFO 2021-01-25 19:48:51,215 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 6; lr: 3.17827; loss: 4.17408; btime(ms): 3577; eta: 0:01:25; peak_mem: 8007M; btime(5iters): 609 ms; rolling_eta: 0:00:14
INFO 2021-01-25 19:48:51,817 tensorboard_hook.py: 188: Logging metrics. Iteration 7
INFO 2021-01-25 19:48:51,819 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 7; lr: 2.70209; loss: 4.15529; btime(ms): 3152; eta: 0:01:12; peak_mem: 8007M; btime(5iters): 607 ms; rolling_eta: 0:00:13
INFO 2021-01-25 19:48:52,423 tensorboard_hook.py: 188: Logging metrics. Iteration 8
INFO 2021-01-25 19:48:52,424 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 8; lr: 2.11763; loss: 4.13425; btime(ms): 2833; eta: 0:01:02; peak_mem: 8007M; btime(5iters): 605 ms; rolling_eta: 0:00:13
INFO 2021-01-25 19:48:53,031 tensorboard_hook.py: 188: Logging metrics. Iteration 9
INFO 2021-01-25 19:48:53,033 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 9; lr: 1.49511; loss: 4.14641; btime(ms): 2586; eta: 0:00:54; peak_mem: 8007M; btime(5iters): 605 ms; rolling_eta: 0:00:12
INFO 2021-01-25 19:48:53,207 log_hooks.py: 416: Average train batch time (ms) for 10 batches: 1524
INFO 2021-01-25 19:48:53,208 log_hooks.py: 425: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:    0.41 ms    0.44 ms
             forward:  122.71 ms  266.00 ms
        loss_compute:    0.96 ms    0.94 ms
     loss_all_reduce:    0.08 ms    0.08 ms
            backward:  227.54 ms  559.92 ms
      optimizer_step:  376.12 ms   44.28 ms
    train_step_total: 1200.40 ms 1200.44 ms
INFO 2021-01-25 19:48:53,636 tensorboard_hook.py: 188: Logging metrics. Iteration 10
INFO 2021-01-25 19:48:53,638 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 10; lr: 0.90932; loss: 4.18362; btime(ms): 2388; eta: 0:00:47; peak_mem: 8007M; btime(5iters): 606 ms; rolling_eta: 0:00:12
INFO 2021-01-25 19:48:54,239 tensorboard_hook.py: 188: Logging metrics. Iteration 11
INFO 2021-01-25 19:48:54,241 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 11; lr: 0.43064; loss: 4.16708; btime(ms): 2226; eta: 0:00:42; peak_mem: 8007M; btime(5iters): 605 ms; rolling_eta: 0:00:11
INFO 2021-01-25 19:48:54,842 tensorboard_hook.py: 188: Logging metrics. Iteration 12
INFO 2021-01-25 19:48:54,843 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 12; lr: 0.11656; loss: 4.13407; btime(ms): 2090; eta: 0:00:37; peak_mem: 8007M; btime(5iters): 604 ms; rolling_eta: 0:00:10
INFO 2021-01-25 19:48:55,449 tensorboard_hook.py: 188: Logging metrics. Iteration 13
INFO 2021-01-25 19:48:55,451 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 13; lr: 0.00484; loss: 4.14517; btime(ms): 1976; eta: 0:00:33; peak_mem: 8007M; btime(5iters): 605 ms; rolling_eta: 0:00:10
INFO 2021-01-25 19:48:56,058 tensorboard_hook.py: 188: Logging metrics. Iteration 14
INFO 2021-01-25 19:48:56,060 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 14; lr: 0.03928; loss: 4.14897; btime(ms): 1879; eta: 0:00:30; peak_mem: 8007M; btime(5iters): 605 ms; rolling_eta: 0:00:09
INFO 2021-01-25 19:48:56,682 tensorboard_hook.py: 188: Logging metrics. Iteration 15
INFO 2021-01-25 19:48:56,684 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 15; lr: 0.1411; loss: 4.14156; btime(ms): 1795; eta: 0:00:26; peak_mem: 8007M; btime(5iters): 609 ms; rolling_eta: 0:00:09
INFO 2021-01-25 19:48:56,685 trainer_main.py: 194: Meters synced
INFO 2021-01-25 19:48:56,714 log_hooks.py: 416: Average train batch time (ms) for 15 batches: 1250
INFO 2021-01-25 19:48:56,714 log_hooks.py: 425: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:    1.63 ms    1.66 ms
             forward:   85.81 ms  234.71 ms
        loss_compute:    0.90 ms    0.88 ms
     loss_all_reduce:    0.07 ms    0.08 ms
            backward:  140.99 ms  490.35 ms
      optimizer_step:  392.73 ms   43.91 ms
    train_step_total:  963.55 ms  963.59 ms
INFO 2021-01-25 19:49:02,998 io.py:  56: Saving data to file: ./checkpoints/metrics.json
INFO 2021-01-25 19:49:03,001 io.py:  70: Saved data to file: ./checkpoints/metrics.json
INFO 2021-01-25 19:49:03,001 log_hooks.py: 283: [phase: 0] Saving checkpoint to ./checkpoints
INFO 2021-01-25 19:49:03,371 log_hooks.py: 312: Saved checkpoint: ./checkpoints/model_phase0.torch
INFO 2021-01-25 19:49:03,371 log_hooks.py: 316: Creating symlink...
INFO 2021-01-25 19:49:03,371 log_hooks.py: 320: Created symlink: ./checkpoints/checkpoint.torch
INFO 2021-01-25 19:49:03,372 __init__.py:  72: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 500, 'total_size': 500, 'shuffle': True}
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-01-25 19:49:10,289 trainer_main.py: 296: Phase advanced. Rank: 0
INFO 2021-01-25 19:49:10,289 state_update_hooks.py:  98: Starting phase 1 [train]
INFO 2021-01-25 19:49:11,696 tensorboard_hook.py: 188: Logging metrics. Iteration 16
INFO 2021-01-25 19:49:11,709 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 16; lr: 0.29803; loss: 4.14494; btime(ms): 2622; eta: 0:00:36; peak_mem: 5673M; btime(5iters): 3493 ms; rolling_eta: 0:00:48
INFO 2021-01-25 19:49:12,485 tensorboard_hook.py: 188: Logging metrics. Iteration 17
INFO 2021-01-25 19:49:12,499 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 17; lr: 0.49122; loss: 4.14275; btime(ms): 2514; eta: 0:00:32; peak_mem: 5673M; btime(5iters): 3531 ms; rolling_eta: 0:00:45
INFO 2021-01-25 19:49:13,213 tensorboard_hook.py: 188: Logging metrics. Iteration 18
INFO 2021-01-25 19:49:13,216 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 18; lr: 0.69747; loss: 4.13617; btime(ms): 2414; eta: 0:00:28; peak_mem: 5673M; btime(5iters): 3552 ms; rolling_eta: 0:00:42
INFO 2021-01-25 19:49:13,845 tensorboard_hook.py: 188: Logging metrics. Iteration 19
INFO 2021-01-25 19:49:13,847 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 19; lr: 0.89198; loss: 4.136; btime(ms): 2320; eta: 0:00:25; peak_mem: 5673M; btime(5iters): 3557 ms; rolling_eta: 0:00:39
INFO 2021-01-25 19:49:14,456 tensorboard_hook.py: 188: Logging metrics. Iteration 20
INFO 2021-01-25 19:49:14,458 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 20; lr: 1.0514; loss: 4.16664; btime(ms): 2235; eta: 0:00:22; peak_mem: 5673M; btime(5iters): 3554 ms; rolling_eta: 0:00:35
INFO 2021-01-25 19:49:15,070 tensorboard_hook.py: 188: Logging metrics. Iteration 21
INFO 2021-01-25 19:49:15,072 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 21; lr: 1.15658; loss: 4.13782; btime(ms): 2158; eta: 0:00:19; peak_mem: 5673M; btime(5iters): 672 ms; rolling_eta: 0:00:06
INFO 2021-01-25 19:49:15,674 tensorboard_hook.py: 188: Logging metrics. Iteration 22
INFO 2021-01-25 19:49:15,676 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 22; lr: 1.19487; loss: 4.11828; btime(ms): 2087; eta: 0:00:16; peak_mem: 5673M; btime(5iters): 635 ms; rolling_eta: 0:00:05
INFO 2021-01-25 19:49:16,288 tensorboard_hook.py: 188: Logging metrics. Iteration 23
INFO 2021-01-25 19:49:16,290 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 23; lr: 1.16167; loss: 4.12; btime(ms): 2023; eta: 0:00:14; peak_mem: 5673M; btime(5iters): 614 ms; rolling_eta: 0:00:04
INFO 2021-01-25 19:49:16,900 tensorboard_hook.py: 188: Logging metrics. Iteration 24
INFO 2021-01-25 19:49:16,902 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 24; lr: 1.06098; loss: 4.189; btime(ms): 1964; eta: 0:00:11; peak_mem: 5673M; btime(5iters): 611 ms; rolling_eta: 0:00:03
INFO 2021-01-25 19:49:17,078 log_hooks.py: 416: Average train batch time (ms) for 10 batches: 678
INFO 2021-01-25 19:49:17,078 log_hooks.py: 425: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:   60.26 ms   60.28 ms
             forward:   27.82 ms  179.48 ms
        loss_compute:    1.01 ms    0.99 ms
     loss_all_reduce:    0.09 ms    0.09 ms
            backward:   22.86 ms  388.28 ms
      optimizer_step:  451.73 ms   86.86 ms
    train_step_total:  734.44 ms  734.47 ms
INFO 2021-01-25 19:49:17,509 tensorboard_hook.py: 188: Logging metrics. Iteration 25
INFO 2021-01-25 19:49:17,511 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 25; lr: 0.90489; loss: 4.154; btime(ms): 1910; eta: 0:00:09; peak_mem: 5673M; btime(5iters): 610 ms; rolling_eta: 0:00:03
INFO 2021-01-25 19:49:18,126 tensorboard_hook.py: 188: Logging metrics. Iteration 26
INFO 2021-01-25 19:49:18,128 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 26; lr: 0.71216; loss: 4.17906; btime(ms): 1860; eta: 0:00:07; peak_mem: 5673M; btime(5iters): 611 ms; rolling_eta: 0:00:02
INFO 2021-01-25 19:49:18,742 tensorboard_hook.py: 188: Logging metrics. Iteration 27
INFO 2021-01-25 19:49:18,744 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 27; lr: 0.50593; loss: 4.18055; btime(ms): 1814; eta: 0:00:05; peak_mem: 5673M; btime(5iters): 613 ms; rolling_eta: 0:00:01
INFO 2021-01-25 19:49:19,351 tensorboard_hook.py: 188: Logging metrics. Iteration 28
INFO 2021-01-25 19:49:19,353 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 28; lr: 0.31099; loss: 4.1435; btime(ms): 1771; eta: 0:00:03; peak_mem: 5673M; btime(5iters): 612 ms; rolling_eta: 0:00:01
INFO 2021-01-25 19:49:19,968 tensorboard_hook.py: 188: Logging metrics. Iteration 29
INFO 2021-01-25 19:49:19,971 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 29; lr: 0.15075; loss: 4.14251; btime(ms): 1731; eta: 0:00:01; peak_mem: 5673M; btime(5iters): 613 ms; rolling_eta: 0:00:00
INFO 2021-01-25 19:49:20,605 tensorboard_hook.py: 188: Logging metrics. Iteration 30
INFO 2021-01-25 19:49:20,607 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 30; lr: 0.04446; loss: 4.1306; btime(ms): 1695; eta: 0:00:00; peak_mem: 5673M; btime(5iters): 619 ms; rolling_eta: 0:00:00
INFO 2021-01-25 19:49:20,608 trainer_main.py: 194: Meters synced
INFO 2021-01-25 19:49:20,608 log_hooks.py: 416: Average train batch time (ms) for 15 batches: 687
INFO 2021-01-25 19:49:20,608 log_hooks.py: 425: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:   42.41 ms   42.43 ms
             forward:   21.99 ms  177.50 ms
        loss_compute:    0.92 ms    0.89 ms
     loss_all_reduce:    0.08 ms    0.09 ms
            backward:   18.18 ms  389.82 ms
      optimizer_step:  440.32 ms   69.23 ms
    train_step_total:  687.53 ms  687.57 ms
INFO 2021-01-25 19:49:26,668 io.py:  56: Saving data to file: ./checkpoints/metrics.json
INFO 2021-01-25 19:49:26,670 io.py:  70: Saved data to file: ./checkpoints/metrics.json
INFO 2021-01-25 19:49:26,671 log_hooks.py: 283: [phase: 1] Saving checkpoint to ./checkpoints
INFO 2021-01-25 19:49:27,047 log_hooks.py: 312: Saved checkpoint: ./checkpoints/model_final_checkpoint_phase1.torch
INFO 2021-01-25 19:49:27,047 log_hooks.py: 316: Creating symlink...
Error in symlink - [Errno 17] File exists: './checkpoints/model_final_checkpoint_phase1.torch' -&gt; './checkpoints/checkpoint.torch'
INFO 2021-01-25 19:49:27,047 log_hooks.py: 320: Created symlink: ./checkpoints/checkpoint.torch
INFO 2021-01-25 19:49:27,270 train.py: 103: All Done!
INFO 2021-01-25 19:49:27,270 logger.py:  66: Shutting down loggers...
INFO 2021-01-25 19:49:27,271 run_distributed_engines.py: 133: All Done!
INFO 2021-01-25 19:49:27,271 logger.py:  66: Shutting down loggers...
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we are done!! We have a SimCLR model trained and available in <code>checkpoints/model_final_checkpoint_phase1.torch</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-logs,-checkpoints,-metrics">Training logs, checkpoints, metrics<a class="anchor-link" href="#Training-logs,-checkpoints,-metrics">¶</a></h2><p>VISSL dumps model checkpoints in the checkpoint directory specified by user. In above example, we used <code>./checkpoints</code> directory. Let's take a look at the content of directory.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ls</span> <span class="n">checkpoints</span><span class="o">/</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-cyan-intense-fg ansi-bold">checkpoint.torch</span>@  metrics.json                         model_phase0.torch
log.txt            model_final_checkpoint_phase1.torch  <span class="ansi-blue-intense-fg ansi-bold">tb_logs</span>/
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We notice:</p>
<ul>
<li>model checkpoints <code>.torch</code> files after every epoch, </li>
<li>model training log <code>log.txt</code> which has the full stdout but saved in file</li>
<li><code>metrics.json</code> if your training calculated some metrics, those metrics values will be saved there..</li>
<li><code>tb_logs</code> which are the tensorboard events</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Visualizing-Tensorboard-Logs">Visualizing Tensorboard Logs<a class="anchor-link" href="#Visualizing-Tensorboard-Logs">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you have enabled <code>config.TENSORBOARD_SETUP.USE_TENSORBOARD=true</code> , you will see the tensorboard events dumped in <code>tb_logs/</code> directory. You can use this to visualize the events in tensorboard as follows:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Look at training curves in tensorboard:</span>
<span class="o">!</span><span class="nb">kill</span> <span class="m">490</span>
<span class="o">%</span><span class="k">reload_ext</span> tensorboard
<span class="o">%</span><span class="k">tensorboard</span> --logdir checkpoints/tb_logs
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>/bin/bash: line 0: kill: (490) - No such process
</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_html rendered_html output_subarea">
<div id="root"></div>
<script>
      (function() {
        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};
        window.TENSORBOARD_ENV["IN_COLAB"] = true;
        document.querySelector("base").href = "https://localhost:6009";
        function fixUpTensorboard(root) {
          const tftb = root.querySelector("tf-tensorboard");
          // Disable the fragment manipulation behavior in Colab. Not
          // only is the behavior not useful (as the iframe's location
          // is not visible to the user), it causes TensorBoard's usage
          // of `window.replace` to navigate away from the page and to
          // the `localhost:<port>` URL specified by the base URI, which
          // in turn causes the frame to (likely) crash.
          tftb.removeAttribute("use-hash");
        }
        function executeAllScripts(root) {
          // When `script` elements are inserted into the DOM by
          // assigning to an element's `innerHTML`, the scripts are not
          // executed. Thus, we manually re-insert these scripts so that
          // TensorBoard can initialize itself.
          for (const script of root.querySelectorAll("script")) {
            const newScript = document.createElement("script");
            newScript.type = script.type;
            newScript.textContent = script.textContent;
            root.appendChild(newScript);
            script.remove();
          }
        }
        function setHeight(root, height) {
          // We set the height dynamically after the TensorBoard UI has
          // been initialized. This avoids an intermediate state in
          // which the container plus the UI become taller than the
          // final width and cause the Colab output frame to be
          // permanently resized, eventually leading to an empty
          // vertical gap below the TensorBoard UI. It's not clear
          // exactly what causes this problematic intermediate state,
          // but setting the height late seems to fix it.
          root.style.height = `${height}px`;
        }
        const root = document.getElementById("root");
        fetch(".")
          .then((x) => x.text())
          .then((html) => void (root.innerHTML = html))
          .then(() => fixUpTensorboard(root))
          .then(() => executeAllScripts(root))
          .then(() => setHeight(root, 800));
      })();
    </script>
</div>
</div>
</div>
</div>
</div>
</div></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><div class="social"><a class="github-button" href="https://github.com/facebookresearch/vissl" data-count-href="https://github.com/facebookresearch/vissl/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star VISSL on GitHub">vissl</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2021 Your Name or Your Company Name<br/>Legal:<a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></section></footer></div></body></html>
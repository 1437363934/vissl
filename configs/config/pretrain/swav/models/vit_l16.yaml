# @package _global_
config:
  DATA:
    TRAIN:
      BATCHSIZE_PER_REPLICA: 16
  MODEL:
    TRUNK:
      NAME: vision_transformer
      TRUNK_PARAMS:
        VISION_TRANSFORMERS:
          IMAGE_SIZE: 224
          PATCH_SIZE: 16
          NUM_LAYERS: 24
          NUM_HEADS: 16
          HIDDEN_DIM: 1024
          MLP_DIM: 4096
          DROPOUT_RATE: 0.1
          ATTENTION_DROPOUT_RATE: 0
          CLASSIFIER: token
    HEAD:
      PARAMS: [
      ["swav_head", {"dims": [1024, 2048, 128], "use_bn": True, "num_clusters":
        [3000]}],
      ]
    TEMP_FROZEN_PARAMS_ITER_MAP: [
    ['module.heads.0.prototypes0.weight', 313],
    ]